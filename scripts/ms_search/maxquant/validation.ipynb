{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# MaxQuant Mutant Peptide Channel Enrichment\n",
    "\n",
    "For each detected mutant evidence row, parses the **Proteins** column to find\n",
    "which mutation the peptide is consistent with, looks up which TMT channels carry\n",
    "that mutation (via per-sample FASTAs), then computes:\n",
    "\n",
    "> **ratio = mean RI in channels that SHOULD have the mutation /\n",
    ">            mean RI in channels that should NOT**\n",
    "\n",
    "Mutant proteins in MaxQuant's `Proteins` column have the format\n",
    "`{accession}-{swap}-{hash}` (e.g. `Q8N4T8-L70M-DC40`), produced by\n",
    "`combine_plex_fastas.py` for Philosopher/TMT-Integrator compatibility.\n",
    "This lets us parse `(accession, swap)` directly from that column.\n",
    "\n",
    "Input: `combined/txt/evidence.txt` from a MaxQuant TMT11 search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# ── CONFIG ────────────────────────────────────────────────────────────────────\n",
    "PLEX_ID     = \"01CPTAC_CCRCC_Proteome_JHU_20171007\"\n",
    "RESULTS_DIR = f\"/scratch/leduc.an/AAS_Evo/MQ_SEARCH/results/{PLEX_ID}\"\n",
    "REPO_DIR    = \"/home/leduc.an/AAS_Evo_project/AAS_Evo\"\n",
    "TMT_MAP     = f\"{REPO_DIR}/metadata/PDC_meta/pdc_file_tmt_map.tsv\"\n",
    "GDC_META    = f\"{REPO_DIR}/metadata/GDC_meta/gdc_meta_matched.tsv\"\n",
    "FASTA_DIR   = \"/scratch/leduc.an/AAS_Evo/FASTA/per_sample\"\n",
    "\n",
    "EVIDENCE_FILE = os.path.join(RESULTS_DIR, \"combined\", \"txt\", \"evidence.txt\")\n",
    "print(f\"Evidence file: {EVIDENCE_FILE}\")\n",
    "\n",
    "# ── LOAD EVIDENCE ─────────────────────────────────────────────────────────────\n",
    "ev = pd.read_csv(EVIDENCE_FILE, sep=\"\\t\", low_memory=False)\n",
    "print(f\"Total evidence rows: {len(ev):,}\")\n",
    "\n",
    "# ── DETECT REPORTER INTENSITY COLUMNS ─────────────────────────────────────────\n",
    "# TMT11 channel order matches isobaricLabels order in mqpar.xml:\n",
    "# idx 1=126C, 2=127N, 3=127C, 4=128N, 5=128C, 6=129N, 7=129C,\n",
    "#     8=130N, 9=130C, 10=131N, 11=131C\n",
    "RI_CHANNEL_ORDER = [\"126C\",\"127N\",\"127C\",\"128N\",\"128C\",\n",
    "                    \"129N\",\"129C\",\"130N\",\"130C\",\"131N\",\"131C\"]\n",
    "CHANNEL_TO_IDX   = {ch: i + 1 for i, ch in enumerate(RI_CHANNEL_ORDER)}\n",
    "\n",
    "def find_ri_cols(df):\n",
    "    \"\"\"Return {channel: column_name} for reporter intensity columns.\"\"\"\n",
    "    for prefix in (\"Reporter intensity corrected\", \"Reporter intensity\"):\n",
    "        found = {ch: f\"{prefix} {idx}\"\n",
    "                 for ch, idx in CHANNEL_TO_IDX.items()\n",
    "                 if f\"{prefix} {idx}\" in df.columns}\n",
    "        if found:\n",
    "            print(f\"Using prefix: '{prefix}'  ({len(found)} channels found)\")\n",
    "            return found\n",
    "    ri_like = [c for c in df.columns if \"reporter\" in c.lower() or \"intensity\" in c.lower()]\n",
    "    print(\"WARNING: no standard reporter intensity columns found. Intensity-like columns:\")\n",
    "    for c in ri_like[:20]: print(f\"  {c}\")\n",
    "    return {}\n",
    "\n",
    "ri_col_map = find_ri_cols(ev)\n",
    "print(f\"RI column map: {ri_col_map}\")\n",
    "\n",
    "# ── PARSE MUTANT PROTEINS FROM Proteins COLUMN ────────────────────────────────\n",
    "# Mutant entries: accession-swap-hash  e.g. Q8N4T8-L70M-DC40\n",
    "# Reference entries: plain accession   e.g. P04637\n",
    "_MUT_PAT = re.compile(r'^([A-Z][A-Z0-9]{4,9})-([A-Z][0-9]+[A-Z])-([A-Z0-9]{4})$')\n",
    "\n",
    "def parse_mutant_proteins(proteins_str):\n",
    "    \"\"\"Return set of (accession, swap) from a MaxQuant Proteins field.\"\"\"\n",
    "    if pd.isna(proteins_str):\n",
    "        return set()\n",
    "    pairs = set()\n",
    "    for entry in str(proteins_str).split(\";\"):\n",
    "        m = _MUT_PAT.match(entry.strip())\n",
    "        if m:\n",
    "            pairs.add((m.group(1), m.group(2)))\n",
    "    return pairs\n",
    "\n",
    "ev[\"_mut_pairs\"] = ev[\"Proteins\"].map(parse_mutant_proteins)\n",
    "mut_mask = ev[\"_mut_pairs\"].map(bool)   # True if any mutant protein found\n",
    "mut_all  = ev[mut_mask].copy()\n",
    "\n",
    "ri_cols = list(ri_col_map.values())\n",
    "if ri_cols:\n",
    "    nonzero_mask = (mut_all[ri_cols].fillna(0) > 0).any(axis=1)\n",
    "    mut_ev = mut_all[nonzero_mask].copy()\n",
    "else:\n",
    "    mut_ev = mut_all.copy()\n",
    "\n",
    "print(f\"\\nMutant evidence rows (any RI > 0): {len(mut_ev):,}  \"\n",
    "      f\"(of {len(mut_all):,} mutant, {len(ev):,} total)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "# ── BUILD MUTATION → CHANNELS MAP (from per-sample FASTAs) ───────────────────\n# Per-sample FASTAs use the original header format:\n#   >mut|{accession}|{gene}|{swap}|{source}|{case_id}|{sample_type}\n# which carries the patient identity needed to map mutation → TMT channel.\n\nTMT_CHANNEL_MAP = {\n    \"tmt_126\":\"126C\", \"tmt_127n\":\"127N\", \"tmt_127c\":\"127C\",\n    \"tmt_128n\":\"128N\",\"tmt_128c\":\"128C\", \"tmt_129n\":\"129N\",\n    \"tmt_129c\":\"129C\",\"tmt_130n\":\"130N\", \"tmt_130c\":\"130C\",\n    \"tmt_131\":\"131N\", \"tmt_131c\":\"131C\",\n}\n\ntmt = pd.read_csv(TMT_MAP, sep=\"\\t\")\ngdc = pd.read_csv(GDC_META, sep=\"\\t\")\n\n# Resolve GDC UUID column — may be 'gdc_file_id' or 'file_id' depending on\n# which version of the metadata pipeline generated the file.\nif \"gdc_file_id\" in gdc.columns:\n    uuid_col = \"gdc_file_id\"\nelif \"file_id\" in gdc.columns:\n    gdc = gdc.rename(columns={\"file_id\": \"gdc_file_id\"})\n    uuid_col = \"gdc_file_id\"\nelse:\n    raise ValueError(f\"Cannot find UUID column in GDC metadata. \"\n                     f\"Columns present: {list(gdc.columns)}\")\nprint(f\"GDC UUID column: '{uuid_col}'\")\n\nplex_tmt = (tmt[tmt[\"run_metadata_id\"] == PLEX_ID]\n            [[\"tmt_channel\",\"case_submitter_id\",\"sample_type\"]].drop_duplicates())\nplex_tmt = plex_tmt[~plex_tmt[\"case_submitter_id\"].str.lower()\n                    .isin([\"ref\",\"reference\",\"pooled\",\"pool\",\"nan\"])]\nplex_tmt[\"channel\"] = plex_tmt[\"tmt_channel\"].map(TMT_CHANNEL_MAP)\n\n# Diagnostic: check sample_type values align between TMT map and GDC metadata\ntmt_sample_types = set(plex_tmt[\"sample_type\"].dropna().str.lower().unique())\ngdc_sample_types = set(gdc[\"sample_type\"].dropna().str.lower().unique())\noverlap = tmt_sample_types & gdc_sample_types\nprint(f\"TMT map sample_type values:  {sorted(tmt_sample_types)}\")\nprint(f\"GDC meta sample_type values: {sorted(gdc_sample_types)}\")\nif not overlap:\n    print(\"WARNING: No sample_type overlap — merge will produce all NaN UUIDs! \"\n          \"Check normalization of sample_type in both files.\")\nelse:\n    print(f\"sample_type overlap (OK):    {sorted(overlap)}\")\n\nplex_meta = plex_tmt.merge(\n    gdc[[\"gdc_file_id\",\"case_submitter_id\",\"sample_type\"]],\n    on=[\"case_submitter_id\",\"sample_type\"], how=\"left\")\n\nn_matched = plex_meta[\"gdc_file_id\"].notna().sum()\nn_total   = len(plex_meta)\nprint(f\"\\nTMT channels in plex:        {n_total}\")\nprint(f\"  matched to GDC UUID:       {n_matched}\")\nprint(f\"  no GDC match (NaN UUID):   {n_total - n_matched}\")\n\nall_patient_channels = set(plex_meta[\"channel\"].dropna().tolist())\nprint(f\"All patient channels ({len(all_patient_channels)}): {sorted(all_patient_channels)}\")\n\nmutation_to_channels = defaultdict(set)   # (accession, swap) → {channels}\nmissing_fastas = []\n# Only channels where a per-sample FASTA was found are included in the ratio\n# universe. Channels with no GDC match or missing FASTA are excluded from both\n# the numerator and denominator so they don't dilute the ratio computation.\nchannels_with_fastas = set()\n\nfor _, row in plex_meta.iterrows():\n    uuid, channel = row[\"gdc_file_id\"], row[\"channel\"]\n    if pd.isna(uuid) or pd.isna(channel):\n        continue\n    fasta_path = os.path.join(FASTA_DIR, f\"{uuid}_mutant.fasta\")\n    if not os.path.exists(fasta_path):\n        missing_fastas.append(uuid)\n        continue\n    channels_with_fastas.add(channel)\n    with open(fasta_path) as f:\n        for line in f:\n            if not line.startswith(\">\"):\n                continue\n            parts = line[1:].strip().split(\"|\")\n            if len(parts) >= 4 and parts[0] == \"mut\":\n                mutation_to_channels[(parts[1], parts[3])].add(channel)\n\nprint(f\"Channels with per-sample FASTA ({len(channels_with_fastas)}): {sorted(channels_with_fastas)}\")\nn_excluded = len(all_patient_channels - channels_with_fastas)\nif n_excluded:\n    print(f\"  Excluded from ratio universe (no FASTA): \"\n          f\"{sorted(all_patient_channels - channels_with_fastas)}\")\nprint(f\"Unique (accession, swap) mutations mapped: {len(mutation_to_channels):,}\")\nprint(f\"Missing per-sample FASTAs:                 {len(missing_fastas)}\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── LOAD VAF PER (accession, swap, channel) ────────────────────────────────\n",
    "\n",
    "MISSENSE  = \"/scratch/leduc.an/AAS_Evo/VEP/all_missense_mutations.tsv\"\n",
    "REF_FASTA = \"/scratch/leduc.an/AAS_Evo/SEQ_FILES/uniprot_human_canonical.fasta\"\n",
    "\n",
    "AA3TO1 = {\n",
    "    \"Ala\":\"A\",\"Arg\":\"R\",\"Asn\":\"N\",\"Asp\":\"D\",\"Cys\":\"C\",\"Gln\":\"Q\",\"Glu\":\"E\",\n",
    "    \"Gly\":\"G\",\"His\":\"H\",\"Ile\":\"I\",\"Leu\":\"L\",\"Lys\":\"K\",\"Met\":\"M\",\"Phe\":\"F\",\n",
    "    \"Pro\":\"P\",\"Ser\":\"S\",\"Thr\":\"T\",\"Trp\":\"W\",\"Tyr\":\"Y\",\"Val\":\"V\",\n",
    "}\n",
    "\n",
    "def parse_hgvsp_to_swap(hgvsp):\n",
    "    m = re.search(r'p\\.([A-Z][a-z]{2})(\\d+)([A-Z][a-z]{2})', str(hgvsp))\n",
    "    if m:\n",
    "        ref = AA3TO1.get(m.group(1))\n",
    "        alt = AA3TO1.get(m.group(3))\n",
    "        if ref and alt:\n",
    "            return f\"{ref}{m.group(2)}{alt}\"\n",
    "    return None\n",
    "\n",
    "gene_to_acc = {}\n",
    "with open(REF_FASTA) as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\">\"):\n",
    "            m = re.search(r'GN=(\\S+)', line)\n",
    "            if m:\n",
    "                gene_to_acc[m.group(1)] = line.split(\"|\")[1]\n",
    "print(f\"Gene → accession entries: {len(gene_to_acc):,}\")\n",
    "\n",
    "uuid_to_channel = plex_meta.dropna(subset=[\"gdc_file_id\",\"channel\"]) \\\n",
    "                            .set_index(\"gdc_file_id\")[\"channel\"].to_dict()\n",
    "\n",
    "missense = pd.read_csv(MISSENSE, sep=\"\\t\", low_memory=False)\n",
    "plex_missense = missense[missense[\"sample_id\"].isin(uuid_to_channel)]\n",
    "print(f\"Missense rows for this plex: {len(plex_missense):,}\")\n",
    "\n",
    "mutation_channel_vaf = {}\n",
    "for _, vrow in plex_missense.iterrows():\n",
    "    vaf     = vrow.get(\"VAF\", np.nan)\n",
    "    channel = uuid_to_channel.get(vrow[\"sample_id\"])\n",
    "    if pd.isna(vaf) or not channel:\n",
    "        continue\n",
    "    acc  = gene_to_acc.get(str(vrow.get(\"SYMBOL\", \"\")))\n",
    "    swap = parse_hgvsp_to_swap(str(vrow.get(\"HGVSp\", \"\")))\n",
    "    if acc and swap:\n",
    "        mutation_channel_vaf[(acc, swap, channel)] = float(vaf)\n",
    "\n",
    "print(f\"(accession, swap, channel) VAF entries: {len(mutation_channel_vaf):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "# ── COMPUTE CHANNEL ENRICHMENT RATIO PER MUTANT EVIDENCE ROW ─────────────────\n# ratio     : mean RI(have channels) / mean RI(not-have channels)\n# ratio_vaf : VAF-weighted mean RI(have channels) / mean RI(not-have channels)\n#\n# Universe = channels_with_fastas: only channels where we have genomic data\n# (per-sample FASTA). Channels with no GDC match or missing FASTA are excluded\n# from both numerator and denominator so they don't dilute the ratio.\n# Reference/pooled channels are already excluded (filtered in cell 2).\n#\n# All-zero RI rows were already removed above.\n# Channels with RI = 0 are included in the average (0s are valid signal).\n# Channels with RI = NaN are excluded.\n\nif \"mutation_channel_vaf\" not in dir():\n    print(\"NOTE: VAF cell not run — ratio_vaf will be NaN for all rows.\")\n    mutation_channel_vaf = {}\n\nprint(f\"Ratio universe — channels with FASTA ({len(channels_with_fastas)}): \"\n      f\"{sorted(channels_with_fastas)}\")\n\nPRECURSOR_CANDIDATES = [\"Intensity\", \"MS/MS count\"]\nprecursor_col = next((c for c in PRECURSOR_CANDIDATES if c in mut_ev.columns), None)\nif precursor_col:\n    nonzero_prec = (mut_ev[precursor_col].fillna(0) > 0).sum()\n    print(f\"Precursor intensity: '{precursor_col}'  ({nonzero_prec:,} / {len(mut_ev):,} non-zero)\")\nelse:\n    print(f\"WARNING: no precursor intensity column found. Checked: {PRECURSOR_CANDIDATES}\")\n\nresults = []\nn_no_mutations = n_no_channel_info = n_cant_split = 0\n\nfor _, row in mut_ev.iterrows():\n    mutations = row[\"_mut_pairs\"]\n    if not mutations:\n        n_no_mutations += 1; continue\n\n    have_channels = set()\n    for mut_key in mutations:\n        have_channels |= mutation_to_channels.get(mut_key, set())\n    # Restrict to channels where we have FASTA data (the ratio universe)\n    have_channels     &= channels_with_fastas\n    not_have_channels  = channels_with_fastas - have_channels\n\n    if not have_channels or not not_have_channels:\n        n_cant_split += 1; continue\n\n    have_ri = [(ch, row[ri_col_map[ch]])\n               for ch in have_channels\n               if ch in ri_col_map and pd.notna(row[ri_col_map[ch]])]\n    not_ri  = [row[ri_col_map[ch]]\n               for ch in not_have_channels\n               if ch in ri_col_map and pd.notna(row[ri_col_map[ch]])]\n\n    if not have_ri or not not_ri:\n        n_no_channel_info += 1; continue\n\n    mean_not  = np.mean(not_ri)\n    mean_have = np.mean([r for _, r in have_ri])\n    ratio     = mean_have / mean_not if mean_not > 0 else np.nan\n\n    weighted_pairs = []\n    for ch, ri_val in have_ri:\n        vaf = None\n        for acc, sw in mutations:\n            v = mutation_channel_vaf.get((acc, sw, ch))\n            if v is not None:\n                vaf = v; break\n        if vaf is not None:\n            weighted_pairs.append((ri_val, vaf))\n\n    ratio_vaf = (np.average([r for r, _ in weighted_pairs],\n                             weights=[w for _, w in weighted_pairs]) / mean_not\n                 if weighted_pairs and mean_not > 0 else np.nan)\n\n    prec_intens = float(row[precursor_col]) \\\n        if (precursor_col and pd.notna(row.get(precursor_col))\n            and row.get(precursor_col, 0) > 0) else np.nan\n\n    results.append({\n        \"Peptide\":             row.get(\"Sequence\", \"\"),\n        \"n_have_ch\":           len(have_channels),\n        \"n_not_have_ch\":       len(not_have_channels),\n        \"mean_have_ri\":        mean_have,\n        \"mean_not_ri\":         mean_not,\n        \"ratio\":               ratio,\n        \"ratio_vaf\":           ratio_vaf,\n        \"precursor_intensity\": prec_intens,\n    })\n\nratios = pd.DataFrame(results).dropna(subset=[\"ratio\"])\nprint(f\"\\nRows with computable ratio:         {len(ratios):,}  (of {len(mut_ev):,} mutant rows)\")\nprint(f\"  of which with VAF-weighted ratio: {ratios['ratio_vaf'].notna().sum():,}\")\nprint(f\"  with precursor intensity:         {ratios['precursor_intensity'].notna().sum():,}\")\nprint(f\"  Skipped — no mutation key:        {n_no_mutations}\")\nprint(f\"  Skipped — no channel split:       {n_cant_split}\")\nprint(f\"  Skipped — RI data missing:        {n_no_channel_info}\")\nprint(f\"\\nUnweighted ratio summary:\")\nprint(ratios[\"ratio\"].describe().round(2))\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── PLOT: enrichment ratio histograms ─────────────────────────────────────────\n",
    "\n",
    "r_unw  = ratios[\"ratio\"].replace(0, np.nan).dropna()\n",
    "r_vaf  = ratios[\"ratio_vaf\"].replace(0, np.nan).dropna()\n",
    "r_spec = ratios.loc[ratios[\"n_have_ch\"] == 1, \"ratio\"].replace(0, np.nan).dropna()\n",
    "\n",
    "all_vals = pd.concat([r_unw, r_vaf]) if len(r_vaf) else r_unw\n",
    "bins     = np.logspace(np.log10(all_vals.clip(lower=1e-3).min()),\n",
    "                       np.log10(all_vals.max()), 60)\n",
    "bins_spec = (np.logspace(np.log10(r_spec.clip(lower=1e-3).min()),\n",
    "                         np.log10(r_spec.max()), 60)\n",
    "             if len(r_spec) else bins)\n",
    "\n",
    "med_unw  = r_unw.median()\n",
    "med_vaf  = r_vaf.median()  if len(r_vaf)  else None\n",
    "med_spec = r_spec.median() if len(r_spec) else None\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 4), sharey=False)\n",
    "panels = [\n",
    "    (axes[0], r_unw,  med_unw,  bins,      \"All rows — Unweighted\",                   \"#4878d0\"),\n",
    "    (axes[1], r_vaf,  med_vaf,  bins,      \"All rows — VAF-weighted\",                 \"#6acc65\"),\n",
    "    (axes[2], r_spec, med_spec, bins_spec, \"Channel-specific (n_have=1)\\nUnweighted\", \"#e07b39\"),\n",
    "]\n",
    "\n",
    "for ax, data, med, b, title, color in panels:\n",
    "    if len(data) == 0:\n",
    "        ax.text(0.5, 0.5, \"No data\", ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "    else:\n",
    "        ax.hist(data, bins=b, color=color, edgecolor=\"white\", linewidth=0.4)\n",
    "        ax.axvline(x=1,   color=\"grey\",    linestyle=\"--\", linewidth=1.2, label=\"ratio = 1\")\n",
    "        ax.axvline(x=med, color=\"#e74c3c\", linestyle=\"-\",  linewidth=1.5,\n",
    "                   label=f\"median = {med:.2f}\")\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.legend(fontsize=8)\n",
    "    ax.set_xlabel(\"mean RI (have) / mean RI (not-have)  [log scale]\")\n",
    "    ax.set_ylabel(\"Number of mutant evidence rows\")\n",
    "    ax.set_title(f\"{title}\\n(n={len(data):,})\")\n",
    "\n",
    "fig.suptitle(f\"Per-row channel enrichment — {PLEX_ID}\", fontsize=11, y=1.02)\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(RESULTS_DIR, \"mutant_channel_enrichment.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"{'Metric':<32} {'Unweighted':>11} {'VAF-weighted':>13} {'n_have=1':>10}\")\n",
    "print(\"-\" * 68)\n",
    "for label, d1, d2, d3 in [\n",
    "    (\"Median ratio\",\n",
    "     f\"{med_unw:.2f}\", f\"{med_vaf:.2f}\" if med_vaf else \"—\", f\"{med_spec:.2f}\" if med_spec else \"—\"),\n",
    "    (\"% ratio > 1\",\n",
    "     f\"{100*(r_unw>1).mean():.1f}%\", f\"{100*(r_vaf>1).mean():.1f}%\" if len(r_vaf) else \"—\",\n",
    "     f\"{100*(r_spec>1).mean():.1f}%\" if len(r_spec) else \"—\"),\n",
    "    (\"% ratio > 2\",\n",
    "     f\"{100*(r_unw>2).mean():.1f}%\", f\"{100*(r_vaf>2).mean():.1f}%\" if len(r_vaf) else \"—\",\n",
    "     f\"{100*(r_spec>2).mean():.1f}%\" if len(r_spec) else \"—\"),\n",
    "    (\"% ratio > 5\",\n",
    "     f\"{100*(r_unw>5).mean():.1f}%\", f\"{100*(r_vaf>5).mean():.1f}%\" if len(r_vaf) else \"—\",\n",
    "     f\"{100*(r_spec>5).mean():.1f}%\" if len(r_spec) else \"—\"),\n",
    "    (\"N rows\", f\"{len(r_unw):,}\", f\"{len(r_vaf):,}\", f\"{len(r_spec):,}\"),\n",
    "]:\n",
    "    print(f\"{label:<32} {d1:>11} {d2:>13} {d3:>10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── PER-MUTATION SUMMARY TABLE ─────────────────────────────────────────────────\n",
    "# One row per detected mutation.\n",
    "\n",
    "score_col          = \"PEP\" if \"PEP\" in ev.columns else (\"Score\" if \"Score\" in ev.columns else None)\n",
    "score_lower_better = score_col != \"Score\"\n",
    "print(f\"Score column: '{score_col}'  (lower better: {score_lower_better})\")\n",
    "\n",
    "pep_prec_intens = defaultdict(list)   # seq → [precursor intensities]\n",
    "pep_scores_all  = defaultdict(list)   # seq → [score values]\n",
    "for _, row in ev.iterrows():\n",
    "    seq = str(row.get(\"Sequence\", \"\")).upper().strip()\n",
    "    if not seq: continue\n",
    "    pi = row.get(precursor_col, np.nan) if precursor_col else np.nan\n",
    "    sc = row.get(score_col, np.nan)     if score_col     else np.nan\n",
    "    if not pd.isna(pi) and float(pi) > 0:\n",
    "        pep_prec_intens[seq].append(float(pi))\n",
    "    if not pd.isna(sc):\n",
    "        pep_scores_all[seq].append(float(sc))\n",
    "\n",
    "all_detected_seqs = set(ev[\"Sequence\"].str.upper().str.strip().dropna())\n",
    "\n",
    "# Group evidence rows by (accession, swap)\n",
    "mut_key_to_ev_rows = defaultdict(list)\n",
    "for _, row in mut_ev.iterrows():\n",
    "    for mut_key in row[\"_mut_pairs\"]:\n",
    "        mut_key_to_ev_rows[mut_key].append(row)\n",
    "\n",
    "def derive_ref_candidates(mut_pep, swap):\n",
    "    m = re.match(r'^([A-Z])(\\d+)([A-Z])$', str(swap))\n",
    "    if not m: return []\n",
    "    ref_aa, mut_aa = m.group(1), m.group(3)\n",
    "    pep = str(mut_pep).upper()\n",
    "    return [pep[:i] + ref_aa + pep[i+1:] for i, aa in enumerate(pep) if aa == mut_aa]\n",
    "\n",
    "mut_info = {}              # (accession, swap) → {mut_pep, ref_pep, ref_detected}\n",
    "ref_pep_to_mut_keys = defaultdict(set)\n",
    "\n",
    "for (accession, swap), rows_list in mut_key_to_ev_rows.items():\n",
    "    pep_counts = defaultdict(int)\n",
    "    for r in rows_list:\n",
    "        pep_counts[str(r.get(\"Sequence\", \"\")).upper().strip()] += 1\n",
    "    mut_pep = max(pep_counts, key=pep_counts.get) if pep_counts else None\n",
    "    if not mut_pep: continue\n",
    "\n",
    "    ref_cands   = [rc.upper() for rc in derive_ref_candidates(mut_pep, swap)]\n",
    "    ref_pep_det = next((rc for rc in ref_cands if rc in all_detected_seqs), None)\n",
    "    ref_pep_use = ref_pep_det or (ref_cands[0] if ref_cands else None)\n",
    "\n",
    "    mut_info[(accession, swap)] = {\n",
    "        \"mut_pep\":      mut_pep,\n",
    "        \"ref_pep\":      ref_pep_use,\n",
    "        \"ref_detected\": (ref_pep_det is not None) if ref_cands else None,\n",
    "    }\n",
    "    if ref_pep_use:\n",
    "        ref_pep_to_mut_keys[ref_pep_use].add((accession, swap))\n",
    "\n",
    "summary_rows = []\n",
    "for (accession, swap), channels in mutation_to_channels.items():\n",
    "    info = mut_info.get((accession, swap))\n",
    "    if not info: continue\n",
    "\n",
    "    mut_pep = info[\"mut_pep\"]\n",
    "    ref_pep = info[\"ref_pep\"]\n",
    "\n",
    "    vafs     = [mutation_channel_vaf[(accession, swap, ch)]\n",
    "                for ch in channels if (accession, swap, ch) in mutation_channel_vaf]\n",
    "    plex_vaf = np.mean(vafs) if vafs else np.nan\n",
    "\n",
    "    other_muts = set()\n",
    "    if ref_pep:\n",
    "        for other_key in ref_pep_to_mut_keys.get(ref_pep, set()):\n",
    "            if other_key != (accession, swap):\n",
    "                other_muts.add(f\"{other_key[0]}:{other_key[1]}\")\n",
    "\n",
    "    rows_list    = mut_key_to_ev_rows[(accession, swap)]\n",
    "    mut_intens   = pep_prec_intens.get(mut_pep, [])\n",
    "    ref_intens   = pep_prec_intens.get(ref_pep, []) if ref_pep else []\n",
    "    other_intens = []\n",
    "    for om_key in other_muts:\n",
    "        om_acc, om_sw = om_key.split(\":\", 1)\n",
    "        om_inf = mut_info.get((om_acc, om_sw))\n",
    "        if om_inf:\n",
    "            other_intens += pep_prec_intens.get(om_inf[\"mut_pep\"], [])\n",
    "\n",
    "    total_site = sum(mut_intens) + sum(ref_intens) + sum(other_intens)\n",
    "    mut_frac   = sum(mut_intens) / total_site if total_site > 0 else np.nan\n",
    "    ref_frac   = sum(ref_intens) / total_site if total_site > 0 else np.nan\n",
    "\n",
    "    scores  = pep_scores_all.get(mut_pep, [])\n",
    "    best_sc = (min(scores) if score_lower_better else max(scores)) if scores else np.nan\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"accession\":           accession,\n",
    "        \"swap\":                swap,\n",
    "        \"n_channels\":          len(channels),\n",
    "        \"plex_vaf\":            plex_vaf,\n",
    "        \"n_evidence_rows\":     len(rows_list),\n",
    "        \"mut_peptide\":         mut_pep,\n",
    "        \"ref_peptide\":         ref_pep,\n",
    "        \"ref_detected\":        info[\"ref_detected\"],\n",
    "        \"other_muts_at_site\":  \"; \".join(sorted(other_muts)) or \"\",\n",
    "        \"mut_site_fraction\":   mut_frac,\n",
    "        \"ref_site_fraction\":   ref_frac,\n",
    "        \"mean_prec_intensity\": np.mean(mut_intens) if mut_intens else np.nan,\n",
    "        score_col or \"score\":  best_sc,\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(summary_rows)\n",
    "print(f\"Per-mutation summary: {len(summary):,} mutations with evidence rows\")\n",
    "print(f\"  ref_detected = True:  {summary['ref_detected'].eq(True).sum():,}\")\n",
    "print(f\"  ref_detected = False: {summary['ref_detected'].eq(False).sum():,}\")\n",
    "print(f\"\\nMS-level allele fraction:\")\n",
    "print(summary[\"mut_site_fraction\"].describe().round(3))\n",
    "display(summary.sort_values(\"mut_site_fraction\", ascending=False).head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── DETECTION RATE BY VAF BIN ──────────────────────────────────────────────────\n",
    "\n",
    "detected_keys  = set(mut_key_to_ev_rows.keys())\n",
    "ref_det_lookup = {k: v[\"ref_detected\"] for k, v in mut_info.items()}\n",
    "\n",
    "all_mut_rows = []\n",
    "for (accession, swap), channels in mutation_to_channels.items():\n",
    "    vafs = [mutation_channel_vaf[(accession, swap, ch)]\n",
    "            for ch in channels if (accession, swap, ch) in mutation_channel_vaf]\n",
    "    all_mut_rows.append({\n",
    "        \"accession\":    accession,\n",
    "        \"swap\":         swap,\n",
    "        \"n_channels\":   len(channels),\n",
    "        \"plex_vaf\":     np.mean(vafs) if vafs else np.nan,\n",
    "        \"mut_detected\": (accession, swap) in detected_keys,\n",
    "        \"ref_detected\": ref_det_lookup.get((accession, swap)),\n",
    "    })\n",
    "\n",
    "all_mut_df = pd.DataFrame(all_mut_rows)\n",
    "has_vaf    = all_mut_df.dropna(subset=[\"plex_vaf\"]).copy()\n",
    "\n",
    "VAF_EDGES  = [0, 0.10, 0.20, 0.30, 0.50, 1.001]\n",
    "VAF_LABELS = [\"0.00–0.10\",\"0.10–0.20\",\"0.20–0.30\",\"0.30–0.50\",\"0.50–1.00\"]\n",
    "has_vaf[\"vaf_bin\"] = pd.cut(has_vaf[\"plex_vaf\"], bins=VAF_EDGES, labels=VAF_LABELS)\n",
    "\n",
    "print(f\"All mutations in plex FASTA: {len(all_mut_df):,}  (with VAF: {len(has_vaf):,})\")\n",
    "print()\n",
    "print(f\"  {'VAF bin':<12} {'Total':>7}  {'Mut det':>8}  {'Det%':>6}  {'Ref det|mut':>12}  {'Ref%|mut':>9}\")\n",
    "print(\"  \" + \"-\" * 60)\n",
    "\n",
    "def _row(label, grp):\n",
    "    n_tot   = len(grp)\n",
    "    n_mdet  = grp[\"mut_detected\"].sum()\n",
    "    det_pct = f\"{100*n_mdet/n_tot:.1f}%\" if n_tot else \"—\"\n",
    "    det_grp = grp[grp[\"mut_detected\"]]\n",
    "    n_rdet  = det_grp[\"ref_detected\"].eq(True).sum()\n",
    "    ref_pct = f\"{100*n_rdet/len(det_grp):.1f}%\" if len(det_grp) else \"—\"\n",
    "    print(f\"  {label:<12} {n_tot:>7,}  {n_mdet:>8,}  {det_pct:>6}  {n_rdet:>12,}  {ref_pct:>9}\")\n",
    "\n",
    "for b in VAF_LABELS:\n",
    "    _row(b, has_vaf[has_vaf[\"vaf_bin\"] == b])\n",
    "print(\"  \" + \"-\" * 60)\n",
    "_row(\"ALL w/ VAF\", has_vaf)\n",
    "_row(\"ALL\",        all_mut_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── PLOT: ratio by precursor intensity quintile ────────────────────────────────\n",
    "\n",
    "r_prec = ratios.dropna(subset=[\"precursor_intensity\"]).copy()\n",
    "r_prec = r_prec[r_prec[\"precursor_intensity\"] > 0]\n",
    "\n",
    "if len(r_prec) < 10:\n",
    "    print(f\"Insufficient data: only {len(r_prec)} rows have precursor intensity > 0.\")\n",
    "else:\n",
    "    log_intens = np.log10(r_prec[\"precursor_intensity\"])\n",
    "    try:\n",
    "        r_prec[\"intens_bin\"] = pd.qcut(log_intens, q=5, duplicates=\"drop\")\n",
    "    except ValueError:\n",
    "        r_prec[\"intens_bin\"] = pd.qcut(log_intens, q=4, duplicates=\"drop\")\n",
    "\n",
    "    bin_order   = list(r_prec[\"intens_bin\"].cat.categories)\n",
    "    panel_specs = [\n",
    "        (\"ratio\",     \"All rows — Unweighted\",                       \"#4878d0\", r_prec),\n",
    "        (\"ratio_vaf\", \"All rows — VAF-weighted\",                     \"#6acc65\",\n",
    "         r_prec[r_prec[\"ratio_vaf\"].notna()]),\n",
    "        (\"ratio\",     \"Channel-specific (n_have=1)\\nUnweighted\",     \"#e07b39\",\n",
    "         r_prec[r_prec[\"n_have_ch\"] == 1]),\n",
    "    ]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=False)\n",
    "    for ax, (col, title, color, df) in zip(axes, panel_specs):\n",
    "        data_by_bin = []\n",
    "        tick_labels = []\n",
    "        for b in bin_order:\n",
    "            grp = df[df[\"intens_bin\"] == b][col].replace(0, np.nan).dropna()\n",
    "            data_by_bin.append(grp.values if len(grp) else np.array([np.nan]))\n",
    "            tick_labels.append(f\"10^{b.left:.1f}–\\n10^{b.right:.1f}\\n(n={len(grp):,})\")\n",
    "        ax.boxplot(\n",
    "            data_by_bin, patch_artist=True, showfliers=True,\n",
    "            flierprops=dict(marker=\".\", markersize=2, alpha=0.25, color=color),\n",
    "            medianprops=dict(color=\"#e74c3c\", linewidth=2),\n",
    "            boxprops=dict(facecolor=color, alpha=0.45),\n",
    "            whiskerprops=dict(color=\"grey\", linewidth=1),\n",
    "            capprops=dict(color=\"grey\", linewidth=1),\n",
    "        )\n",
    "        ax.axhline(y=1, color=\"grey\", linestyle=\"--\", linewidth=1.2, label=\"ratio = 1\")\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.set_xticks(range(1, len(bin_order) + 1))\n",
    "        ax.set_xticklabels(tick_labels, fontsize=7.5)\n",
    "        ax.set_xlabel(f\"Precursor intensity ('{precursor_col}') — low → high\", fontsize=9)\n",
    "        ax.set_ylabel(\"mean RI (have) / mean RI (not-have)  [log scale]\")\n",
    "        ax.set_title(f\"{title}\\n(n = {df[col].replace(0,np.nan).dropna().__len__():,})\")\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"Channel enrichment vs precursor intensity — {PLEX_ID}\\n\"\n",
    "        \"(Flat trend → background RI noise is NOT the main cause of diluted ratios)\",\n",
    "        fontsize=10, y=1.03)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(RESULTS_DIR, \"mutant_channel_enrichment_intensity.pdf\"),\n",
    "                bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}